---
title: "Statistical Genetics and Bioinformatics Coursework"
author: "CID: 06010948"
date: "2025.4.15"
output:
  pdf_document:
    fig_width: 5.5
    fig_height: 3.8
    fig_crop: true  
   
---
    
<style type="text/css">
h1{
  font-size: 24pt;
}
h2{
  font-size: 18pt;
}
body{
  font-size: 12pt;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Question 1

### 1.1

**Mathematical equation**

Given that \(ABF = \sqrt{\frac{V}{W + V}}\exp\left\{\frac{\hat{\beta}^{2}}{2}\frac{W}{V(V + W)}\right\}\), where \(\hat{\beta}\) is the maximum - likelihood estimate (MLE) of the logistic regression, \(V\) is the variance of \(\hat{\beta}\), and \(W\) is the variance parameter in the prior distribution \(N(0, W)\) (here, the prior distribution is centered at \(0\), corresponding to the null distribution of no association).
Also, since \(Z^{2}=\frac{\hat{\beta}^{2}}{V}\) (the usual Wald statistic), the equation can also be written as \(ABF = \sqrt{\frac{V}{W + V}}\exp\left\{\frac{Z^{2}}{2}\frac{W}{(V + W)}\right\}\). The ABF is the ratio of marginal likelihoods: \(ABF = \frac{P(\text{data} \mid H_1)}{P(\text{data} \mid H_0)}\), when ABF > 1: the data favor the alternative hypothesis; when ABF < 1: the data favor the null hypothesis.

**Null Hypothesis**

The null hypothesis \(H_0\) being tested is: \(H_0:\beta = 0\), which means that there is no association between the SNP under study and the response variable.

**Basis for Rejecting the Null Hypothesis**

In Bayesian factor analysis, including the use of Approximate Bayes Factors (ABFs), the strength of evidence is commonly interpreted as follows: when \(1 < \text{ABF} < 3\), there is weak evidence in favor of the alternative hypothesis, suggesting a possible but uncertain association; when \(3 \leq \text{ABF} < 5\), the evidence is of moderate strength, indicating a potential statistical association; and when \(\text{ABF} \geq 5\), there is strong evidence supporting the alternative hypothesis, providing grounds to reject the null hypothesis.

In studies of SNP-disease associations, such as liver cancer risk analysis, SNPs with \(\text{ABF} \geq 3\) are typically considered as potential candidates of interest, while \(\text{ABF} \geq 5\) serves as a stricter threshold for confirmed associations—comparable to the conventional genome-wide significance level of \(p < 5 \times 10^{-8}\). 

It is important to note that thresholds may be adjusted depending on the research goal—such as preliminary screening or clinical biomarker development—highlighting the flexibility of Bayesian methods and their adaptability to different study contexts.




### 1.2

**Choice of prior distribution(s) and its effect on the final list of selected SNPs**

In the context of computing ABFs, the prior variance \(W\) plays an important role. A smaller prior variance \(W\) implies a more concentrated prior distribution around the null value (\(\beta = 0\)). This makes it more difficult to reject the null hypothesis, as the prior strongly favors the null. As a result, only SNPs with very large effect sizes (and thus large \(\beta\) values) will have high ABF values and be selected as associated with the trait. On the other hand, a larger prior variance \(W\) means a more diffuse prior distribution. This makes it easier to reject the null hypothesis, since the prior places less weight on the null value. So, more SNPs may be selected as associated with the trait, even those with relatively smaller effect sizes.


**The plot of the relationship between prior variance and the number of associated SNPs**

```{r message=FALSE, warning=FALSE}
# Load data
part1_data <- read.table("6010948_q1_part1.txt", header=TRUE)
y <- part1_data$y
X <- part1_data[, -1]  # Remove the response variable column

# Calculate regression coefficients (beta) and standard errors (SE) for each SNP
results <- lapply(1:ncol(X), function(i) {
  model <- glm(y ~ X[,i], family=binomial())
  c(beta = coef(model)[2], 
    se = summary(model)$coefficients[2,2],
    pvalue = summary(model)$coefficients[2,4])
})
results <- as.data.frame(do.call(rbind, results))
```



```{r}
# Add SNP names
rownames(results) <- colnames(X)

# Define ABF calculation function
abf.fn <- function(beta, V, W) {
  p <- sqrt(V / (W + V))
  q <- W / (V * (V + W))
  p * exp(q * beta ^ 2 / 2)
}

# Set a series of different prior variance W values
W_values <- seq(0.01, 1, by = 0.1)

# Calculate ABF for each W value
abf_matrix <- sapply(W_values, function(W) {
  abf.fn(results$beta, results$se^2, W)
})
colnames(abf_matrix) <- paste0("W=", W_values)

# Count significant SNPs (ABF>5)
sig_counts <- apply(abf_matrix, 2, function(x) sum(x > 5))
```






```{r warning=FALSE}
# Plot the relationship between prior variance and number of significant SNPs
library(ggplot2)
ggplot(data.frame(W=factor(W_values), Count=sig_counts), 
       aes(x=W, y=Count, group=1)) +
  geom_line(color="steelblue", linewidth=1.2) +
  geom_point(linewidth=3) +
  labs(x="Prior Variance (W)", 
       y="Number of Significant SNPs (ABF>5)",
       title="Effect of Prior Variance on SNP Selection") +
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
```

As shown in the figure, when the prior variance \(W\) is small (e.g., around 0.01), the number of significant SNPs (ABF > 5) is low. This is because a small \(W\) implies a prior distribution tightly centered around zero, strongly favoring the null hypothesis. Only SNPs with very large effect sizes can overcome this prior, leading to fewer detections.

As \(W\) increases (e.g., around 0.11), the number of significant SNPs rises sharply. A larger \(W\) reflects a more diffuse prior, reducing the weight near zero and allowing SNPs with smaller effects to be considered significant. This aligns with the principle that larger prior variances make it easier to reject the null hypothesis.

However, when \(W\) becomes too large, the number of significant SNPs starts to decline. This may be due to increased influence from noise in the data. Although the prior allows for larger effect sizes, it also admits more uncertainty, making it harder to distinguish true signals from random fluctuations. As a result, the number of meaningful SNPs no longer increases and may even decrease.




**The top 10 SNPs associated with liver cancer(when w=0.11)**
```{r}
# Output significant SNP results (using W=0.11 as example)
W_selected <- 0.11
abf_values <- abf_matrix[, paste0("W=", W_selected)]
significant_snps <- cbind(results, ABF=abf_values)  # Add ABF column to results

# Filter significant SNPs and sort
significant_snps <- significant_snps[abf_values > 5, ]
significant_snps <- significant_snps[order(-significant_snps$ABF), ]  # Sort by ABF in descending order

# Display only top 10 significant SNPs
significant_snps_show <- head(significant_snps, 10)

# Print results
cat("Number of significant SNPs (ABF>5) with W=", W_selected, ":", 
    nrow(significant_snps), "\n\n")
print(significant_snps_show)
```










### 1.3

**Definition of PRS**

A polygenic risk score (PRS) quantifies an individual’s genetic predisposition to a particular disease by summing the effects of multiple genetic variants (SNPs), weighted by their effect sizes (typically log - odds ratios from a GWAS). Mathematically, for an individual \(i\):
\[PRS_i=\sum_{j = 1}^{m}\hat{\beta}_j\cdot G_{ij}\]
Where:

\(\hat{\beta}_j\) is the estimated effect size (regression coefficient) of SNP \(j\),

\(G_{ij}\in\{0,1,2\}\) is the genotype of individual \(i\) at SNP \(j\) (number of minor alleles),

\(m\) is the number of selected SNPs used in the score.

**Steps to Compute PRS and estimated probabilities of developing liver cancer**

1. Select SNPs: Use SNPs with strong evidence of association (e.g., those with \(ABF>5\) from part 2 and \(W = 0.11\)).<br>
2. Extract genotypes of 20 new individuals: We already have the structure from part1 data.<br>
3. Compute PRS: Multiply genotype values by their corresponding \(\beta\) from the GWAS and sum across all selected SNPs.<br>
4. Estimate Probabilities: Assuming logistic regression, transform PRS to disease probabilities using:
\[ \hat{P}_i=\frac{e^{\alpha + PRS_i}}{1 + e^{\alpha+PRS_i}}\]
Where \(\alpha\) is the intercept (can be set to 0 for relative risk comparison). 


**The PRS and estimated probabilities of the given individuals in developing liver cancer**

```{r}
# Load part 2 data
part2_data <- read.table("6010948_q1_part2.txt", header = TRUE)

# Extract names of significant SNPs
sig_snp_names <- rownames(significant_snps)

# Extract beta values of significant SNPs
beta_sig <- significant_snps$beta
names(beta_sig) <- sig_snp_names

# Extract genotypes of these SNPs in new individuals
G_new <- part2_data[, sig_snp_names]

# Calculate PRS for each individual
prs_scores <- as.vector(as.matrix(G_new) %*% beta_sig)

# Set intercept to 0 for risk comparison
alpha <- 0  

# Calculate probability of developing liver cancer for each individual
probabilities <- 1 / (1 + exp(-(alpha + prs_scores)))

# Output results
prs_df <- data.frame(Individual = 1:nrow(G_new),
                     PRS = prs_scores,
                     Probability = probabilities)
print(prs_df)
```





```{r}
# Explore the impact of different SNP sets on PRS
# Define different SNP sets: top 50, 100, and 150 significant SNPs
snp_sets <- list(head(sig_snp_names, 50), head(sig_snp_names, 100), head(sig_snp_names, 150))

# Store PRS results calculated from different SNP sets
prs_different_sets <- list()

for (i in 1:length(snp_sets)) {
  current_snp_set <- snp_sets[[i]]
  # Extract genotypes of new individuals for current SNP set
  G_subset <- part2_data[, current_snp_set]
  # Extract beta values corresponding to current SNP set
  beta_subset <- beta_sig[current_snp_set]
  # Calculate PRS for each individual under current SNP set
  prs_subset <- as.vector(as.matrix(G_subset) %*% beta_subset)
  prs_different_sets[[i]] <- prs_subset
}

# Calculate disease probabilities for each individual under different SNP sets
probabilities_different_sets <- list()
for (j in 1:length(prs_different_sets)) {
  current_prs <- prs_different_sets[[j]]
  current_probabilities <- 1 / (1 + exp(-(alpha + current_prs)))
  probabilities_different_sets[[j]] <- current_probabilities
}
```

**Further exploration of impact of different SNP sets on PRS calculation**

```{r}
# Reshape data into long format for ggplot2 visualization
prs_long <- data.frame()
for (j in 1:length(snp_sets)) {
  temp_prs <- data.frame(PRS = prs_different_sets[[j]], 
                         SNP_Set = paste0("SNP_Set_", length(snp_sets[[j]])),
                         Individual = 1:length(prs_different_sets[[j]]))
  prs_long <- rbind(prs_long, temp_prs)
}

# Create boxplot of PRS distributions
ggplot(prs_long, aes(x = SNP_Set, y = PRS)) +
  geom_boxplot() +
  labs(title = "Distribution of PRS for Different SNP Sets",
       x = "Number of SNPs in the Set",
       y = "Polygenic Risk Score") +
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
```

We define different SNP sets, taking the top 50, 100, and 150 significant SNPs respectively in descending order of ABF. The box - plot reveals that different SNP sets have a significant impact on the polygenic risk scores (PRS). The PRS for SNP_Set_150 has the highest median and is generally concentrated in a higher score range, indicating that when a larger number of SNPs are included, the aggregated genetic information is more comprehensive, leading to higher calculated risk scores. In comparison, SNP_Set_100 has a lower median PRS than SNP_Set_150 but higher than SNP_Set_50, suggesting that reducing the number of SNPs results in a decrease in PRS. Furthermore, SNP_Set_50 shows the lowest median PRS, with the scores mostly distributed in a lower range. This implies that using fewer SNPs may fail to capture the full scope of an individual's genetic risk, resulting in notably lower PRS values. Overall, the more SNPs included, the better the PRS reflects an individual's true genetic risk profile. 







